{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import librariesImport\n",
    "# import gedlibpy\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.utils import from_networkx\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "from multiprocessing import Pool\n",
    "from matplotlib import pyplot as plt\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7efbf9eb8650>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_folder = \"./data/\"\n",
    "\n",
    "# Filter graphs with more than max_num_nodes nodes\n",
    "max_num_nodes = 20\n",
    "NUM_WORKER = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Methods for filtering graphs\n",
    "\n",
    "class TimeoutError(Exception):\n",
    "    pass\n",
    "\n",
    "def handler(signum, frame):\n",
    "    raise TimeoutError()\n",
    "\n",
    "def set_x(data_obj):\n",
    "    data_obj.x = torch.ones(data_obj.num_nodes, 1)\n",
    "    return data_obj\n",
    "\n",
    "def node_match(n1, n2):\n",
    "    return np.argmax(n1['x']) == np.argmax(n2['x'])\n",
    "\n",
    "\n",
    "def get_unique_graphs_using_nx(nx_graphs, timeout_duration = 15):\n",
    "    # Filter Isomorphic graphs using nx.is_isomorphic\n",
    "    unique_graphs = [nx_graphs[0]]\n",
    "    \n",
    "    signal.signal(signal.SIGALRM, handler) \n",
    "\n",
    "\n",
    "    print(\"Filtering isomorphic graphs...\")\n",
    "    for i in tqdm(range(1, len(nx_graphs))):\n",
    "        unique = True\n",
    "        for j in range(len(unique_graphs)):\n",
    "            g1 = nx_graphs[i]\n",
    "            g2 = unique_graphs[j]\n",
    "            if g1.number_of_nodes() > g2.number_of_nodes():\n",
    "                g1, g2 = g2, g1\n",
    "\n",
    "            signal.alarm(timeout_duration)\n",
    "            try:\n",
    "                if nx.is_isomorphic(g1, g2, node_match=node_match):\n",
    "                    #print(\"Graph \", i, \" is isomorphic to graph \", j)\n",
    "                    unique = False\n",
    "                    break\n",
    "            except TimeoutError:\n",
    "                print(f\"Timeout for graph {i}\")\n",
    "                unique = False\n",
    "                break\n",
    "            finally:\n",
    "                signal.alarm(0)\n",
    "        if unique:\n",
    "            #print(\"Including graph \", i, \" in unique_graphs\")\n",
    "            unique_graphs.append(nx_graphs[i])\n",
    "    print(f\"Total number of non-isomorphic graphs: {len(unique_graphs)}\")\n",
    "    return unique_graphs\n",
    "\n",
    "\n",
    "def split_and_dump_graphs(nx_graphs, data_path = None, DATASET = \"\"):\n",
    "    print(\"Splitting and dumping graphs...\")\n",
    "    if data_path == None:\n",
    "        print(\"ERROR: Data path not provided\")\n",
    "        return\n",
    "    \n",
    "    random.seed(0)\n",
    "    random.shuffle(nx_graphs)    # Shuffle the list of graphs\n",
    "    train_size = int(0.6*len(nx_graphs))\n",
    "    val_size = int(0.2*len(nx_graphs))\n",
    "    test_size = len(nx_graphs) - train_size - val_size\n",
    "\n",
    "    train_graphs = nx_graphs[:train_size]\n",
    "    val_graphs = nx_graphs[train_size:train_size+val_size]\n",
    "    test_graphs = nx_graphs[train_size+val_size:]\n",
    "    print(f\"Train: {len(train_graphs)}, Val: {len(val_graphs)}, Test: {len(test_graphs)}\")\n",
    "\n",
    "\n",
    "    # Dump Non-isomorphic Graphs \n",
    "    train_data = []\n",
    "    for graph in train_graphs:\n",
    "        data = from_networkx(graph)\n",
    "        train_data.append(data)\n",
    "    torch.save(train_data, data_path + \"train.pt\")\n",
    "    print(f\"saved {DATASET} into {data_path}train.pt\")\n",
    "\n",
    "    val_data = []\n",
    "    for graph in val_graphs:\n",
    "        data = from_networkx(graph)\n",
    "        val_data.append(data)\n",
    "    torch.save(val_data, data_path + \"val.pt\")\n",
    "    print(f\"saved {DATASET} into {data_path}val.pt\")\n",
    "\n",
    "    test_data = []\n",
    "    for graph in test_graphs:\n",
    "        data = from_networkx(graph)\n",
    "        test_data.append(data)\n",
    "    torch.save(test_data, data_path + \"test.pt\")\n",
    "    print(f\"saved {DATASET} into {data_path}test.pt\")\n",
    "\n",
    "\n",
    "def check_leakage(data_path, node_match_fun = None, only_leakage = False):\n",
    "    print(\"Checking for leakage...\")\n",
    "    print(\"loading saved splits from \", data_path)\n",
    "    train_data = torch.load(data_path + \"/train.pt\")\n",
    "    val_data = torch.load(data_path + \"/val.pt\")\n",
    "    test_data = torch.load(data_path + \"/test.pt\")\n",
    "\n",
    "    train_nx = list(map(functools.partial(to_networkx, to_undirected=True, node_attrs = ['x']), train_data))\n",
    "    val_nx = list(map(functools.partial(to_networkx, to_undirected=True, node_attrs = ['x']), val_data))\n",
    "    test_nx = list(map(functools.partial(to_networkx, to_undirected=True, node_attrs = ['x']), test_data))\n",
    "    \n",
    "    print(\"Number of graphs in train: \", len(train_nx), \" Val: \", len(val_nx), \" Test: \", len(test_nx))\n",
    "\n",
    "    if not only_leakage:\n",
    "        cnt = 0\n",
    "        for i in tqdm(range(len(train_nx))):\n",
    "            for j in range(len(train_nx)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if nx.is_isomorphic(train_nx[i], train_nx[j], node_match=node_match):\n",
    "                    #print(\"Isomorphic graph found between train and val\")\n",
    "                    cnt += 1\n",
    "                    break\n",
    "        print(\"Number of duplicate inside train: \", cnt)\n",
    "        \n",
    "        cnt = 0\n",
    "        for i in tqdm(range(len(val_nx))):\n",
    "            for j in range(len(val_nx)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if nx.is_isomorphic(val_nx[i], val_nx[j], node_match=node_match):\n",
    "                    #print(\"Isomorphic graph found between train and val\")\n",
    "                    cnt += 1\n",
    "                    break\n",
    "        print(\"Number of duplicates inside val:\", cnt)\n",
    "        \n",
    "        cnt = 0\n",
    "        for i in tqdm(range(len(test_nx))):\n",
    "            for j in range(len(test_nx)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if nx.is_isomorphic(test_nx[i], test_nx[j], node_match=node_match):\n",
    "                    #print(\"Isomorphic graph found between train and val\")\n",
    "                    cnt += 1\n",
    "                    break\n",
    "        print(\"Number of duplicates inside test:\", cnt)\n",
    "\n",
    "\n",
    "    cnt = 0\n",
    "    for val_g in tqdm(val_nx):\n",
    "        for train_g in train_nx:\n",
    "            if nx.is_isomorphic(train_g, val_g, node_match=node_match):\n",
    "                #print(\"Isomorphic graph found between train and val\")\n",
    "                cnt += 1\n",
    "                break\n",
    "    print(\"Number of leaks in Val from train: \",cnt)\n",
    "\n",
    "    cnt = 0\n",
    "    for test_g in tqdm(test_nx):\n",
    "        for train_g in train_nx:\n",
    "            if nx.is_isomorphic(train_g, test_g, node_match=node_match):\n",
    "                #print(\"Isomorphic graph found between train and val\")\n",
    "                cnt += 1\n",
    "                break\n",
    "    print(\"Number of leaks in test from train: \",cnt)\n",
    "\n",
    "def generate_uniqe_graphs(graphs, DATASET, node_labeled = False, only_leakage = False):\n",
    "    \"\"\"\n",
    "        graphs: list of torch_geometric.data.Data objects\n",
    "            data[i].x: Node features of graph i\n",
    "        DATASET: Name of the dataset\n",
    "\n",
    "    \"\"\"\n",
    "    data_path = './data/'+ DATASET + '/'\n",
    "    if not os.path.isdir(data_path):\n",
    "        os.mkdir(data_path)\n",
    "\n",
    "    print(\"Total number of graphs: \", len(graphs))\n",
    "    print(\"Selecting Small Graphs...\")\n",
    "    graphs = list(filter(lambda x: x.num_nodes <= max_num_nodes, graphs))\n",
    "    print(f\"Graphs with at most {max_num_nodes} nodes: {len(graphs)}\")\n",
    "\n",
    "    if not node_labeled:\n",
    "        graphs = list(map(set_x, graphs))\n",
    "\n",
    "    nx_graphs = list(map(functools.partial(to_networkx, to_undirected=True, node_attrs = ['x']), graphs))\n",
    "\n",
    "    unique_nx_graphs = get_unique_graphs_using_nx(nx_graphs)\n",
    "    sizes = list(map(lambda x: x.number_of_nodes(), unique_nx_graphs))\n",
    "    print(\"Maximum number of nodes in the dataset: \", max(sizes))\n",
    "    split_and_dump_graphs(unique_nx_graphs, data_path, DATASET)\n",
    "    check_leakage(data_path, only_leakage=only_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'AIDS'\n",
    "data = TUDataset(root=\"/tmp/\", name=DATASET)\n",
    "node_labeled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs:  2000\n",
      "Selecting Small Graphs...\n",
      "Graphs with at most 20 nodes: 1666\n",
      "Filtering isomorphic graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1665/1665 [00:18<00:00, 88.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of non-isomorphic graphs: 1588\n",
      "Maximum number of nodes in the dataset:  20\n",
      "Splitting and dumping graphs...\n",
      "Train: 952, Val: 317, Test: 319\n",
      "saved AIDS into ./data/AIDS/train.pt\n",
      "saved AIDS into ./data/AIDS/val.pt\n",
      "saved AIDS into ./data/AIDS/test.pt\n",
      "Checking for leakage...\n",
      "loading saved splits from  ./data/AIDS/\n",
      "Number of graphs in train:  952  Val:  317  Test:  319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 952/952 [00:11<00:00, 79.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate inside train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 317/317 [00:01<00:00, 241.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates inside val: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:01<00:00, 226.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates inside test: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 317/317 [00:03<00:00, 80.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in Val from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:04<00:00, 77.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in test from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_uniqe_graphs(data, DATASET, node_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = torch.load('./data/AIDS/train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[11, 38], edge_index=[2, 24])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB-BINARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'IMDB-BINARY'\n",
    "data = TUDataset(root=\"/tmp/\", name=DATASET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 146], y=[1], num_nodes=20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labeled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs:  1000\n",
      "Selecting Small Graphs...\n",
      "Graphs with at most 20 nodes: 696\n",
      "Filtering isomorphic graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 695/695 [00:01<00:00, 640.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of non-isomorphic graphs: 280\n",
      "Splitting and dumping graphs...\n",
      "Train: 168, Val: 56, Test: 56\n",
      "saved IMDB-BINARY into ./data/IMDB-BINARY/train.pt\n",
      "saved IMDB-BINARY into ./data/IMDB-BINARY/val.pt\n",
      "saved IMDB-BINARY into ./data/IMDB-BINARY/test.pt\n",
      "Checking for leakage...\n",
      "loading saved splits from  ./data/IMDB-BINARY/\n",
      "Number of graphs in train:  168  Val:  56  Test:  56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [00:00<00:00, 648.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate inside train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:00<00:00, 1865.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates inside val: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:00<00:00, 1884.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates inside test: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:00<00:00, 601.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in Val from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:00<00:00, 644.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in test from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_uniqe_graphs(data, DATASET, node_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROTEINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'PROTEINS'\n",
    "data = TUDataset(root=\"/tmp/\", name=DATASET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 162], x=[42, 3], y=[1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labeled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs:  1113\n",
      "Selecting Small Graphs...\n",
      "Graphs with at most 20 nodes: 412\n",
      "Filtering isomorphic graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:00<00:00, 655.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of non-isomorphic graphs: 297\n",
      "Splitting and dumping graphs...\n",
      "Train: 178, Val: 59, Test: 60\n",
      "saved PROTEINS into ./data/PROTEINS/train.pt\n",
      "saved PROTEINS into ./data/PROTEINS/val.pt\n",
      "saved PROTEINS into ./data/PROTEINS/test.pt\n",
      "Checking for leakage...\n",
      "loading saved splits from  ./data/PROTEINS/\n",
      "Number of graphs in train:  178  Val:  59  Test:  60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178/178 [00:00<00:00, 576.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate inside train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:00<00:00, 1516.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates inside val: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 1690.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates inside test: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:00<00:00, 533.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in Val from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 566.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in test from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_uniqe_graphs(data, DATASET, node_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINUX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torch_geometric.datasets.ged_dataset import GEDDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'LINUX'\n",
    "\n",
    "train_data = GEDDataset('/tmp/', name = \"LINUX\")\n",
    "test_data = GEDDataset('/tmp/', name = \"LINUX\", train = False)\n",
    "data = train_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 18], i=[1], num_nodes=8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labeled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs:  1000\n",
      "Selecting Small Graphs...\n",
      "Graphs with at most 20 nodes: 1000\n",
      "Filtering isomorphic graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [00:00<00:00, 1486.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of non-isomorphic graphs: 89\n",
      "Splitting and dumping graphs...\n",
      "Train: 53, Val: 17, Test: 19\n",
      "saved LINUX into ./data/LINUX/train.pt\n",
      "saved LINUX into ./data/LINUX/val.pt\n",
      "saved LINUX into ./data/LINUX/test.pt\n",
      "Checking for leakage...\n",
      "loading saved splits from  ./data/LINUX/\n",
      "Number of graphs in train:  53  Val:  17  Test:  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:00<00:00, 1254.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate inside train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 2633.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates inside val: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 4467.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates inside test: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 1262.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in Val from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 1217.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in test from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_uniqe_graphs(data, DATASET, node_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OGBG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "from torch_geometric.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ogbg-molhiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ogbg-molhiv'\n",
    "data = PygGraphPropPredDataset(name = DATASET) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 40], edge_attr=[40, 3], x=[19, 9], y=[1, 1], num_nodes=19)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452741"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_labeled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs:  41127\n",
      "Selecting Small Graphs...\n",
      "Graphs with at most 20 nodes: 14923\n",
      "Filtering isomorphic graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 8863/14922 [05:50<03:59, 25.26it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_uniqe_graphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATASET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_labeled\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 181\u001b[0m, in \u001b[0;36mgenerate_uniqe_graphs\u001b[0;34m(graphs, DATASET, node_labeled)\u001b[0m\n\u001b[1;32m    177\u001b[0m     graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(set_x, graphs))\n\u001b[1;32m    179\u001b[0m nx_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(functools\u001b[38;5;241m.\u001b[39mpartial(to_networkx, to_undirected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, node_attrs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]), graphs))\n\u001b[0;32m--> 181\u001b[0m unique_nx_graphs \u001b[38;5;241m=\u001b[39m \u001b[43mget_unique_graphs_using_nx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnx_graphs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m split_and_dump_graphs(unique_nx_graphs, data_path, DATASET)\n\u001b[1;32m    183\u001b[0m check_leakage(data_path)\n",
      "Cell \u001b[0;32mIn[12], line 46\u001b[0m, in \u001b[0;36mget_unique_graphs_using_nx\u001b[0;34m(nx_graphs, node_math_fun, timeout_duration)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m         \u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malarm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unique:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m#print(\"Including graph \", i, \" in unique_graphs\")\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     unique_graphs\u001b[38;5;241m.\u001b[39mappend(nx_graphs[i])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_uniqe_graphs(data, DATASET, node_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ogbg-code2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ogbg-code2'\n",
    "data = PygGraphPropPredDataset(name = DATASET) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 243], x=[244, 2], node_is_attributed=[244, 1], node_dfs_order=[244, 1], node_depth=[244, 1], y=[1], num_nodes=244)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 452741/452741 [01:12<00:00, 6253.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number valid graphs in the dataset:  404\n"
     ]
    }
   ],
   "source": [
    "# For OGBA-CODE2 Label adjustment\n",
    "\n",
    "node_labeled = True\n",
    "\n",
    "valid_graphs = []\n",
    "for g in tqdm(data):\n",
    "    if (g.num_nodes <= 20):\n",
    "        labels = g.x[:, 0]\n",
    "        g.x = torch.nn.functional.one_hot(labels, 97).float()\n",
    "        rev1 = torch.stack((g.edge_index[1], g.edge_index[0]), 0)\n",
    "        g.edge_index = torch.cat((g.edge_index, rev1), -1)\n",
    "        valid_graphs.append(g)\n",
    "data = valid_graphs\n",
    "print(\"Total number valid graphs in the dataset: \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs:  404\n",
      "Selecting Small Graphs...\n",
      "Graphs with at most 20 nodes: 404\n",
      "Filtering isomorphic graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 126/403 [01:05<01:33,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout for graph 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 147/403 [01:20<02:21,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout for graph 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 175/403 [01:36<02:24,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout for graph 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 189/403 [01:56<03:40,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout for graph 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 261/403 [02:13<01:06,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout for graph 261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 321/403 [02:14<00:08,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout for graph 329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 354/403 [03:12<00:34,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout for graph 335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 367/403 [03:27<00:30,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout for graph 359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 369/403 [03:42<00:44,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout for graph 369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 403/403 [03:57<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout for graph 376\n",
      "Total number of non-isomorphic graphs: 181\n",
      "Splitting and dumping graphs...\n",
      "Train: 108, Val: 36, Test: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ogbg-code2 into ./data/ogbg-code2/train.pt\n",
      "saved ogbg-code2 into ./data/ogbg-code2/val.pt\n",
      "saved ogbg-code2 into ./data/ogbg-code2/test.pt\n",
      "Checking for leakage...\n",
      "loading saved splits from  ./data/ogbg-code2/\n",
      "Number of graphs in train:  108  Val:  36  Test:  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 38/108 [04:23<08:06,  6.94s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_uniqe_graphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATASET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_labeled\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 183\u001b[0m, in \u001b[0;36mgenerate_uniqe_graphs\u001b[0;34m(graphs, DATASET, node_labeled)\u001b[0m\n\u001b[1;32m    181\u001b[0m unique_nx_graphs \u001b[38;5;241m=\u001b[39m get_unique_graphs_using_nx(nx_graphs)\n\u001b[1;32m    182\u001b[0m split_and_dump_graphs(unique_nx_graphs, data_path, DATASET)\n\u001b[0;32m--> 183\u001b[0m \u001b[43mcheck_leakage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 113\u001b[0m, in \u001b[0;36mcheck_leakage\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m j:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_isomorphic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_nx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_nx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_match\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m#print(\"Isomorphic graph found between train and val\")\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/nas/saswatmeher/miniconda/envs/torch/lib/python3.8/site-packages/networkx/algorithms/isomorphism/isomorph.py:240\u001b[0m, in \u001b[0;36mis_isomorphic\u001b[0;34m(G1, G2, node_match, edge_match)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NetworkXError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraphs G1 and G2 are not of the same type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m gm \u001b[38;5;241m=\u001b[39m GM(G1, G2, node_match\u001b[38;5;241m=\u001b[39mnode_match, edge_match\u001b[38;5;241m=\u001b[39medge_match)\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_isomorphic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/nas/saswatmeher/miniconda/envs/torch/lib/python3.8/site-packages/networkx/algorithms/isomorphism/isomorphvf2.py:284\u001b[0m, in \u001b[0;36mGraphMatcher.is_isomorphic\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misomorphisms_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/nas/saswatmeher/miniconda/envs/torch/lib/python3.8/site-packages/networkx/algorithms/isomorphism/isomorphvf2.py:294\u001b[0m, in \u001b[0;36mGraphMatcher.isomorphisms_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n\u001b[0;32m--> 294\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch()\n",
      "File \u001b[0;32m/mnt/nas/saswatmeher/miniconda/envs/torch/lib/python3.8/site-packages/networkx/algorithms/isomorphism/isomorphvf2.py:316\u001b[0m, in \u001b[0;36mGraphMatcher.match\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemantic_feasibility(G1_node, G2_node):\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Recursive call, adding the feasible state.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     newstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;28mself\u001b[39m, G1_node, G2_node)\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch()\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# restore data structures\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     newstate\u001b[38;5;241m.\u001b[39mrestore()\n",
      "File \u001b[0;32m/mnt/nas/saswatmeher/miniconda/envs/torch/lib/python3.8/site-packages/networkx/algorithms/isomorphism/isomorphvf2.py:316\u001b[0m, in \u001b[0;36mGraphMatcher.match\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemantic_feasibility(G1_node, G2_node):\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Recursive call, adding the feasible state.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     newstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;28mself\u001b[39m, G1_node, G2_node)\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch()\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# restore data structures\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     newstate\u001b[38;5;241m.\u001b[39mrestore()\n",
      "    \u001b[0;31m[... skipping similar frames: GraphMatcher.match at line 316 (7 times)]\u001b[0m\n",
      "File \u001b[0;32m/mnt/nas/saswatmeher/miniconda/envs/torch/lib/python3.8/site-packages/networkx/algorithms/isomorphism/isomorphvf2.py:316\u001b[0m, in \u001b[0;36mGraphMatcher.match\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemantic_feasibility(G1_node, G2_node):\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Recursive call, adding the feasible state.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     newstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;28mself\u001b[39m, G1_node, G2_node)\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch()\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# restore data structures\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     newstate\u001b[38;5;241m.\u001b[39mrestore()\n",
      "File \u001b[0;32m/mnt/nas/saswatmeher/miniconda/envs/torch/lib/python3.8/site-packages/networkx/algorithms/isomorphism/isomorphvf2.py:319\u001b[0m, in \u001b[0;36mGraphMatcher.match\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch()\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# restore data structures\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m \u001b[43mnewstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/nas/saswatmeher/miniconda/envs/torch/lib/python3.8/site-packages/networkx/algorithms/isomorphism/isomorphvf2.py:928\u001b[0m, in \u001b[0;36mGMState.restore\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# Now we revert the other two vectors.\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;66;03m# Thus, we delete all entries which have this depth level.\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vector \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGM\u001b[38;5;241m.\u001b[39minout_1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGM\u001b[38;5;241m.\u001b[39minout_2):\n\u001b[0;32m--> 928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(vector\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m    929\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m vector[node] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth:\n\u001b[1;32m    930\u001b[0m             \u001b[38;5;28;01mdel\u001b[39;00m vector[node]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_uniqe_graphs(data, DATASET, node_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for leakage...\n",
      "loading saved splits from  ./data/ogbg-code2/\n",
      "Number of graphs in train:  108  Val:  36  Test:  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:25<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in Val from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:08<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaks in test from train:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "check_leakage('./data/ogbg-code2/', only_leakage=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ogbg-molpcba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ogbg-molpcba'\n",
    "data = PygGraphPropPredDataset(name = DATASET) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GED",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
